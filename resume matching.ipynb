{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de85de01-4399-4f31-a981-136034cb2501",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "8f6cd5e0-9615-4cb3-a90d-50e7ed31525f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import spacy\n",
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
    "import string\n",
    "# import matplotlib.pyplot as plt\n",
    "# from wordcloud import WordCloud\n",
    "# from transformers import pipeline\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification, DistilBertModel\n",
    "import torch\n",
    "\n",
    "# import transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fae6758-bb0a-4239-9caa-bf346a11fd8c",
   "metadata": {
    "tags": []
   },
   "source": [
    "# NLP and cleaning fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "846c6bd2-8785-403d-86c0-52ddc94028da",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "stopwords = ENGLISH_STOP_WORDS\n",
    "# lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def clean(doc):\n",
    "    text_no_namedentities = []\n",
    "    document = nlp(doc)\n",
    "    ents = [e.text for e in document.ents]\n",
    "    for item in document:\n",
    "        if item.text in ents:\n",
    "            pass\n",
    "        else:\n",
    "            text_no_namedentities.append(item.text)\n",
    "    doc = (\" \".join(text_no_namedentities))\n",
    "\n",
    "    doc = doc.lower().strip()\n",
    "    doc = doc.replace(\"</br>\", \" \")\n",
    "    doc = doc.replace(\"-\", \" \")\n",
    "    doc = \"\".join([char for char in doc if char not in string.punctuation and not char.isdigit()])\n",
    "    doc = \" \".join([token for token in doc.split() if token not in stopwords])\n",
    "    # doc = \"\".join([lemmatizer.lemmatize(word) for word in doc])\n",
    "    doc=nlp(doc)\n",
    "    doc = \" \".join([word.lemma_ for word in doc])\n",
    "    doc=\" \".join(set((doc.split())))\n",
    "    \n",
    "    return doc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bb8f2d4-e3c2-4d9d-b619-6f63f235538e",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Embedding fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "21af002e-2390-4a90-bbb0-519992045ebb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def embedding(X_train):\n",
    "    model_name = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
    "    model = DistilBertModel.from_pretrained(model_name)\n",
    "    tokenizer = DistilBertTokenizer.from_pretrained(model_name)\n",
    "\n",
    "    # X_train = job_description['job_description'].to_list()\n",
    "    # print(type(X_train))\n",
    "\n",
    "    res = tokenizer(X_train,padding=True, truncation=True, max_length=3, return_tensors=\"pt\")\n",
    "    # print(res)\n",
    "    # len(res)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**res)\n",
    "        # outputs = model(res['input_ids'])\n",
    "        # model?\n",
    "        JD_vects=outputs.last_hidden_state\n",
    "    return JD_vects.reshape(1,-1)\n",
    "    # return JD_vects[0].tolist()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cda2678e-d32e-46e8-aed4-d9f86b4b98d3",
   "metadata": {},
   "source": [
    "# Cosine Similarity Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "6f8c207d-9da9-424c-8cb3-664b3755225f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def cosim(df1,df2):\n",
    "    return cosine_similarity(df1,df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52343c7c-5f49-4689-b6b6-fbc3b31fa210",
   "metadata": {
    "tags": []
   },
   "source": [
    "# import resume and jd csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "bcf0d582-ab0e-4320-afd6-fba8f33e25a5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "resume_data = pd.read_csv(\"resume_data.csv\",index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "4d1ada5a-f615-46a6-ad19-31087e49d1e2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# job_description = pd.read_csv('training_data.csv', chunksize=15)\n",
    "job_description = pd.read_csv('training_data.csv')\n",
    "job_description=job_description.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d8cdd43-f6f9-497c-944d-58ba01e292e1",
   "metadata": {
    "tags": []
   },
   "source": [
    "# clean resume and jd text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "8133c3dc-b810-4ed5-b896-b86053313c10",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "resume_data['Cleaned_Resume']=resume_data['resume_text'].apply(lambda x:clean(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "1b47ee17-4017-4335-8ab7-c56f7649399b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "job_description['Cleaned_JD']=job_description['job_description'].apply(lambda x:clean(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7743365f-23ab-4ef2-b102-7c2ec05c7e00",
   "metadata": {
    "tags": []
   },
   "source": [
    "# embed resume and jd text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "b6e403e9-26eb-4a57-94bc-904e51356f22",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "resume_data['Cleaned_Resume_vector']=resume_data['Cleaned_Resume'].apply(lambda x:embedding(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "478750fb-1a8d-4a77-a659-be4bd3a31263",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "job_description['Cleaned_JD_vector']=job_description['Cleaned_JD'].apply(lambda x:embedding(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7e5b5ff-d641-4fe0-8317-a96486c78887",
   "metadata": {},
   "source": [
    "# resume matching by cosine similarity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "adab409b-db8f-453f-877c-4907a52c157e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter index of a job decription to choose from 0-14:\n",
      " 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Your choice of JD is from Apple\n",
      "\n",
      "Job Description:\n",
      "\n",
      " description\n",
      "as an asc you will be highly influential in growing mind and market share of apple products while building longterm relationships with those who share your passion \n",
      "customer experiences are driven through you and your partner team growing in an ever changing and challenging environment you strive for perfection whether its maintaining visual merchandising or helping to grow and develop your partner team\n",
      "\n",
      "qualifications\n",
      "a passion to help people understand how apple products can enrich their livesexcellent communication skills allowing you to be as comfortable in front of a small group as you are speaking with individuals years preferred working in a dynamic sales andor results driven environment as well as proven success developing customer loyaltyability to encourage a partner team and grow apple business\n",
      "\n",
      "Position for which resumes are shortlisted: Apple Solutions Consultant\n",
      "\n",
      "Shortlisted resume File names are as below\n",
      "\n",
      "53    24799301.pdf\n",
      "89    23568641.pdf\n",
      "23    20628003.pdf\n",
      "57    39718499.pdf\n",
      "56    25857360.pdf\n",
      "Name: File_name, dtype: object\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "choice = int(input(\"Enter index of a job decription to choose from 0-14:\\n\"))\n",
    "\n",
    "if choice <= 14 and choice > 0:\n",
    "    # job_description['company_name']\n",
    "    print(f\"\\nYour choice of JD is from {job_description[job_description['company_name'].index==choice]['company_name'].values[0]}\\n\")\n",
    "    print(f\"Job Description:\\n\\n {job_description[job_description['company_name'].index==choice]['job_description'].values[0]}\\n\")\n",
    "    print(f\"Position for which resumes are shortlisted: {job_description[job_description['company_name'].index==choice]['position_title'].values[0]}\\n\")\n",
    "\n",
    "    resume_data['jd_vector_of_choice'] = resume_data['Cleaned_Resume_vector'].apply(lambda x: cosim(x,job_description['Cleaned_JD_vector'][choice].tolist()))\n",
    "    print(\"Shortlisted resume File names are as below\\n\")\n",
    "    df=(resume_data.sort_values('jd_vector_of_choice', ascending=False)['File_name'].head())    \n",
    "    print(df)\n",
    "    print()\n",
    "else:\n",
    "    print(\"Invalid choice try again\")\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "9c6aca65-d4de-42f4-a528-9bbbc66749b3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category: ACCOUNTANT\n",
      "\n",
      "File Name: 24799301.pdf\n",
      "\n",
      "Resume Content: \n",
      "\n",
      "ACCOUNTANT\n",
      "Summary\n",
      "Accountant for a Medium sized Company\n",
      "Experience\n",
      "01/2009\n",
      " \n",
      "to \n",
      "Current\n",
      "Accountant\n",
      " \n",
      "Company Name\n",
      " \n",
      "ï¼​ \n",
      "City\n",
      " \n",
      ", \n",
      "State\n",
      "Hired by their CPA firm to handle all accounting and job cost Reporting.\n",
      "01/2007\n",
      " \n",
      "to \n",
      "01/2009\n",
      "Accountant\n",
      " \n",
      "Company Name\n",
      " \n",
      "ï¼​ \n",
      "City\n",
      " \n",
      ", \n",
      "State\n",
      "Hired by their CPA firm to handle all accounting functions..\n",
      "01/1997\n",
      " \n",
      "to \n",
      "01/2007\n",
      "Accountant\n",
      " \n",
      "Company Name\n",
      " \n",
      "ï¼​ \n",
      "City\n",
      " \n",
      ", \n",
      "State\n",
      "Installed new Peachtree Accounting System.\n",
      "Installed new computer system using a local area network and Added a Web site.\n",
      "Education and Training\n",
      "1974\n",
      "B.S\n",
      " \n",
      ": \n",
      "Business Administration Accounting\n",
      " \n",
      "University of Cincinnati\n",
      " \n",
      "ï¼​ \n",
      "City\n",
      " \n",
      ", \n",
      "State\n",
      " \n",
      "Business Administration Accounting\n",
      "Interests\n",
      "Annapolis Amblers Walking Club, President &Trailmaster, Maryland Volkssport Assn, President, Chesapeake Civil War Roundtable.\n",
      "Skills\n",
      "accounting, CPA, local area network, Peachtree Accounting, Reporting, Web site\n",
      "Additional Information\n",
      "Interests \n",
      "Annapolis Amblers Walking Club, President &Trailmaster, Maryland Volkssport Assn, President, Chesapeake Civil War\n",
      "Roundtable.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for each in df.to_list():\n",
    "    print('Category: '+resume_data[['Category','File_name']][resume_data['File_name']==each].values[0][0]+'\\n')\n",
    "    print('File Name: '+resume_data[['Category','File_name']][resume_data['File_name']==each].values[0][1]+'\\n')\n",
    "    print('Resume Content: \\n\\n'+resume_data['resume_text'][resume_data['File_name']==each].values[0]+'\\n')\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "206441ad-7d32-4797-af1a-6d139f8a52a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37a9fd7f-3ca9-4401-ab71-cec844911f08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27d0cef5-5cd0-44b9-974c-a6a0ffb49942",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff35b9a-bd99-444f-b0a2-dd3ee6032b48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcafe697-3198-4963-97c0-257f17a07e68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "847abf9d-1bba-404f-af83-b3b273ac0574",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dda1466-b982-462e-bbf3-748f239cd2e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
